{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fd960cc-d941-4ab3-bc2d-7dcb43d41ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: /home/user/21012125/Capstone2/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\n",
      "Output Path: /home/user/21012125/Capstone2/ecg_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export train: 100%|██████████| 17084/17084 [28:32<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] saved 17084 images → /home/user/21012125/Capstone2/ecg_images/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export val: 100%|██████████| 2146/2146 [03:34<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] saved 2146 images → /home/user/21012125/Capstone2/ecg_images/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export test: 100%|██████████| 2158/2158 [03:35<00:00, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] saved 2158 images → /home/user/21012125/Capstone2/ecg_images/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#1. IMPORTS AND PATHS\n",
    "import os, ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wfdb\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")   # headless; prevents notebook/GUI rendering\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()              # just in case; disables interactive mode\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "#set based folder\n",
    "DB = os.path.join(current_dir, \"ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\")\n",
    "OUT_ROOT = os.path.join(current_dir, \"ecg_images\")\n",
    "\n",
    "print(f\"Dataset Path: {DB}\")\n",
    "print(f\"Output Path: {OUT_ROOT}\")\n",
    "\n",
    "FNAME_COL = \"filename_lr\"                      # use low-rate (100 Hz) files\n",
    "SR = 100      # sampling rate for filename_lr\n",
    "# 1600 x 1200\n",
    "TARGET_SIZE = (800, 600)                       # output image width × height (pixels)\n",
    "\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "\n",
    "\n",
    "#2. READ METADATA CSVs\n",
    "df = pd.read_csv(os.path.join(DB, \"ptbxl_database.csv\"))\n",
    "scp = pd.read_csv(os.path.join(DB, \"scp_statements.csv\"), index_col=0)\n",
    "\n",
    "# keep only diagnostic statements\n",
    "diagnostic_codes = scp[scp[\"diagnostic\"] == 1]\n",
    "\n",
    "\n",
    "#3. MAP SCP CODES TO DIAGNOSTIC SUPERCLASS\n",
    "def to_superclasses(scp_codes_str):\n",
    "    codes = ast.literal_eval(scp_codes_str)  # dict: code → weight\n",
    "    diags = [c for c in codes.keys() if c in diagnostic_codes.index]\n",
    "    supers = sorted({diagnostic_codes.loc[c, \"diagnostic_class\"] for c in diags})\n",
    "    return supers\n",
    "\n",
    "df[\"superclasses\"] = df[\"scp_codes\"].apply(to_superclasses)\n",
    "\n",
    "\n",
    "#4. OFFICIAL STRATIFIED FOLDS\n",
    "train_df = df[df[\"strat_fold\"].isin(range(1, 9))].copy()\n",
    "val_df   = df[df[\"strat_fold\"] == 9].copy()\n",
    "test_df  = df[df[\"strat_fold\"] == 10].copy()\n",
    "\n",
    "#5. SINGLE-LABEL PRIMARY CLASS PER RECORD\n",
    "# basically if an entry has multiple super classes, pick one based on the priority shown below\n",
    "PRIORITY = [\"MI\", \"STTC\", \"HYP\", \"CD\", \"NORM\"]\n",
    "\n",
    "# function that picks a super class \n",
    "def choose_primary_superclass(superclasses):\n",
    "    if not superclasses:\n",
    "        return None\n",
    "    for c in PRIORITY:\n",
    "        if c in superclasses:\n",
    "            return c\n",
    "    return superclasses[0]\n",
    "\n",
    "# create a new column called primary class and apply the result of the super class function to it\n",
    "for split in (train_df, val_df, test_df):\n",
    "    split[\"primary_class\"] = split[\"superclasses\"].apply(choose_primary_superclass)\n",
    "\n",
    "# drop the rows that have no primary class \n",
    "train_df = train_df.dropna(subset=[\"primary_class\"])\n",
    "val_df   = val_df.dropna(subset=[\"primary_class\"])\n",
    "test_df  = test_df.dropna(subset=[\"primary_class\"])\n",
    "\n",
    "\n",
    "#6. HELPERS FOR READING WFDB AND SAVING PLOTS\n",
    "def load_signal_and_leads(rec_rel_path, base_dir=DB):\n",
    "    \"\"\"Read WFDB record. Returns (signal[T,12], lead_names[list]).\"\"\"\n",
    "    rec_path = os.path.join(base_dir, rec_rel_path)\n",
    "    sig, meta = wfdb.rdsamp(rec_path)\n",
    "    names = list(meta.sig_name) if hasattr(meta, \"sig_name\") else [f\"Lead{i+1}\" for i in range(sig.shape[1])]\n",
    "    return sig.astype(\"float32\"), names\n",
    "\n",
    "import gc\n",
    "\n",
    "def save_12lead_strip(signal, lead_names, out_path, sr=SR, target_size=TARGET_SIZE):\n",
    "    \"\"\"\n",
    "    Plot 12 leads in a 3×4 grid and save as PNG/JPG without blowing RAM.\n",
    "    \"\"\"\n",
    "    T, C = signal.shape\n",
    "\n",
    "    # Keep the pixel buffer bounded: (figsize * dpi) ≈ target_size\n",
    "    fig_w, fig_h = 10, 6\n",
    "    dpi = max(72, min(target_size[0]/fig_w, target_size[1]/fig_h))\n",
    "\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(fig_w, fig_h), dpi=dpi)\n",
    "    axes = axes.ravel()\n",
    "    try:\n",
    "        t = np.arange(T, dtype=np.float32) / float(sr)\n",
    "        for i in range(min(C, 12)):\n",
    "            ax = axes[i]\n",
    "            ax.plot(t, signal[:, i], linewidth=0.8)\n",
    "            ax.set_xlim(t[0], t[-1])\n",
    "            ax.set_ylim(-3.0, 3.0) #added this to accomodate large hypertrophy spikes without clipping, small signals look small, big signals look big\n",
    "            ax.axis(\"off\")\n",
    "        for j in range(C, len(axes)):\n",
    "            axes[j].axis(\"off\")\n",
    "\n",
    "        # Avoid heavy auto-layout work on huge batches\n",
    "        # plt.tight_layout(pad=0.15)   # optional; comment out for speed\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\", pad_inches=0.03)\n",
    "    finally:\n",
    "        plt.close(fig)     # CRITICAL: frees Agg buffer\n",
    "        del fig, axes      # drop references\n",
    "\n",
    "def export_split_images(split_df, split_name, limit=None, gc_every=200):\n",
    "    \"\"\"Save ECG plots into OUT_ROOT/split_name/<class>/<ecg_id>.jpg.\"\"\"\n",
    "    saved = 0\n",
    "    root = os.path.join(OUT_ROOT, split_name)\n",
    "    for idx, row in tqdm(split_df.iterrows(), total=len(split_df), desc=f\"Export {split_name}\"):\n",
    "        if limit and saved >= limit:\n",
    "            break\n",
    "\n",
    "        label = row[\"primary_class\"]\n",
    "        if not label:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            signal, leads = load_signal_and_leads(row[FNAME_COL])\n",
    "            ecg_id = int(row[\"ecg_id\"]) if \"ecg_id\" in row.index else idx\n",
    "            out_path = os.path.join(root, label, f\"{ecg_id}.jpg\")\n",
    "            save_12lead_strip(signal, leads, out_path)\n",
    "            saved += 1\n",
    "        except Exception:\n",
    "            # optional: log the path or index here\n",
    "            pass\n",
    "        finally:\n",
    "            # Make sure big arrays are eligible for GC immediately\n",
    "            try:\n",
    "                del signal, leads\n",
    "            except NameError:\n",
    "                pass\n",
    "\n",
    "        if saved % gc_every == 0:\n",
    "            gc.collect()\n",
    "\n",
    "    print(f\"[{split_name}] saved {saved} images → {root}\")\n",
    "\n",
    "#7. RUN EXPORT\n",
    "export_split_images(train_df, \"train\", limit=None) #only run this for first time generation, else comment out\n",
    "export_split_images(val_df,   \"val\", limit=None)\n",
    "export_split_images(test_df,  \"test\",limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d836f242-fe5a-4de7-88cc-2733c4f49cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original HYP weight: 7.06\n",
      "Boosted HYP weight:  14.12\n",
      "pos_weight (train-only): {'NORM': 1.2490784623486044, 'MI': 2.9013473395752456, 'STTC': 3.0812231247013857, 'HYP': 14.124587069372346, 'CD': 3.372664448425902}\n"
     ]
    }
   ],
   "source": [
    "#8 COMPUTE CLASS WEIGHTS \n",
    "CLASS_ORDER = [\"NORM\", \"MI\", \"STTC\", \"HYP\", \"CD\"]  # same order as model output\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "#compute pos weight from train only\n",
    "pos_counts = Counter()\n",
    "total_train = len(train_df)\n",
    "\n",
    "for supers in train_df[\"superclasses\"]:\n",
    "    s = set(supers)\n",
    "    for cls in CLASS_ORDER:\n",
    "        if cls in s:\n",
    "            pos_counts[cls] += 1\n",
    "\n",
    "# PyTorch expects per-class pos_weight = N_neg / N_pos\n",
    "pos_weight_np = []\n",
    "for cls in CLASS_ORDER:\n",
    "    p = max(1, pos_counts[cls])  # avoid divide-by-zero\n",
    "    n = total_train - p\n",
    "    pos_weight_np.append(n / p)\n",
    "\n",
    "#manually boosting weights for \"HYP\" because it is performing poorly (0.49)\n",
    "print(f\"Original HYP weight: {pos_weight_np[3]:.2f}\")\n",
    "pos_weight_np[3] *= 2  # Increase penalty for missing HYP \n",
    "print(f\"Boosted HYP weight:  {pos_weight_np[3]:.2f}\")\n",
    "\n",
    "pos_weight = torch.tensor(pos_weight_np, dtype=torch.float32).to(device)\n",
    "print(\"pos_weight (train-only):\", dict(zip(CLASS_ORDER, [float(x) for x in pos_weight_np])))\n",
    "\n",
    "example_weights = []\n",
    "for supers in train_df[\"superclasses\"]:\n",
    "    labels = [cls for cls in CLASS_ORDER if cls in supers]\n",
    "    if not labels:\n",
    "        w = 1.0\n",
    "    else:\n",
    "        w = float(np.mean([pos_weight_np[CLASS_ORDER.index(cls)] for cls in labels]))\n",
    "    example_weights.append(w)\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=torch.tensor(example_weights, dtype=torch.double),\n",
    "    num_samples=len(example_weights),\n",
    "    replacement=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38ffe6e3-0323-4558-b2bd-dca16337a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 17084 rows → /home/user/21012125/Capstone2/ecg_images/train_labels.csv\n",
      "Wrote 2146 rows → /home/user/21012125/Capstone2/ecg_images/val_labels.csv\n",
      "Wrote 2158 rows → /home/user/21012125/Capstone2/ecg_images/test_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "\n",
    "CLASS_ORDER = [\"NORM\", \"MI\", \"STTC\", \"HYP\", \"CD\"]\n",
    "\n",
    "def to_multihot(superclasses):\n",
    "    s = set(superclasses)\n",
    "    return {c: int(c in s) for c in CLASS_ORDER}\n",
    "\n",
    "def build_labels_csv_from_existing(split_df, split_name, out_root=OUT_ROOT):\n",
    "    \"\"\"\n",
    "    create scvs with multihots corresponding to each ecg image, this data should be ready\n",
    "    to be passed as \"tensors\" into the neural network\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # empty rows to store all entries\n",
    "    rows = []\n",
    "    # the directory of the split (train/val/test)\n",
    "    split_dir = os.path.join(out_root, split_name)\n",
    "    # for each entry in the dataframe [id, name, superclass, primaryclass]\n",
    "    for _, r in split_df.iterrows():\n",
    "        # we get the super class\n",
    "        supers = r[\"superclasses\"]          # e.g., ['CD','HYP']\n",
    "        # supers = NORM\n",
    "        # if no superclass, then this entry is meaningless\n",
    "        if not supers:\n",
    "            continue\n",
    "        # get primary class\n",
    "        \n",
    "        primary = r[\"primary_class\"]\n",
    "        # get the id of the ecg\n",
    "        ecg_id = int(r[\"ecg_id\"])\n",
    "        # find the image that we saved that corresponds to the entry we're lookniga t right now\n",
    "        # train / NORM / 1.png\n",
    "        img_path = os.path.join(split_dir, primary, f\"{ecg_id}.jpg\")\n",
    "        if not os.path.exists(img_path):\n",
    "            # might not exist if you used a small 'limit' during export\n",
    "            continue\n",
    "        # creates a multihot row\n",
    "        mh = to_multihot(supers)\n",
    "        row = {\n",
    "            \"image_path\": img_path.replace(\"\\\\\", \"/\"),\n",
    "            \"labels\": json.dumps(sorted(supers))\n",
    "        }   \n",
    "        # add the columns\n",
    "        row.update(mh)                      # add NORM/MI/STTC/HYP/CD columns\n",
    "        # add the rows\n",
    "        rows.append(row)\n",
    "        # we're essentially building a dataframe that has [imagepath, superclass, [superclasses_multihot]]\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    out_csv = os.path.join(out_root, f\"{split_name}_labels.csv\")\n",
    "    df_out.to_csv(out_csv, index=False)\n",
    "    print(f\"Wrote {len(df_out)} rows → {out_csv}\")\n",
    "    return out_csv\n",
    "\n",
    "# build csvs for all splits\n",
    "train_csv = build_labels_csv_from_existing(train_df, \"train\")\n",
    "val_csv   = build_labels_csv_from_existing(val_df,   \"val\")\n",
    "test_csv  = build_labels_csv_from_existing(test_df,  \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fa2ec9a-5b1e-47ac-8301-bb0808a2487c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "OUT_ROOT = os.path.join(current_dir, \"ecg_images\")\n",
    "train_csv = os.path.join(OUT_ROOT, \"train_labels.csv\")\n",
    "val_csv   = os.path.join(OUT_ROOT, \"val_labels.csv\")\n",
    "test_csv  = os.path.join(OUT_ROOT, \"test_labels.csv\")\n",
    "\n",
    "# Class order used everywhere\n",
    "CLASS_ORDER = [\"NORM\", \"MI\", \"STTC\", \"HYP\", \"CD\"]\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a21ae89b-8b67-443d-a116-07be8dad141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17084 2146 2158\n"
     ]
    }
   ],
   "source": [
    "# Transforms & DataLoaders \n",
    "IMG_SIZE = 512  # increased to 512 to capture exact height of spikes\n",
    "IMG_H = 512\n",
    "IMG_W = 512\n",
    "from torchvision import transforms as T  # unify alias as T\n",
    "from ecg_utils import MultiLabelECGImages\n",
    "\n",
    "# Train transforms:\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_H, IMG_W)),\n",
    "    \n",
    "    # CHANGED: Added TrivialAugmentWide.\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std =[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.15)), \n",
    "])\n",
    "\n",
    "\n",
    "# Validation transforms: deterministic (no random augments)\n",
    "val_transforms = T.Compose([\n",
    "    T.Resize((IMG_H, IMG_W)),  # match train size / your model input\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std =[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Test/eval transforms: same as validation\n",
    "eval_transforms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std =[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_ds = MultiLabelECGImages(train_csv, transform=train_transforms)\n",
    "val_ds   = MultiLabelECGImages(val_csv,   transform=val_transforms)\n",
    "test_ds  = MultiLabelECGImages(test_csv,  transform=eval_transforms)\n",
    "\n",
    "# DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 8 \n",
    "\n",
    "# Use the balanced sampler if you created 'train_sampler' earlier.\n",
    "# If you did NOT create it, set sampler=None and use shuffle=True.\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,        # <- FIXED name\n",
    "    sampler=train_sampler,        # <- requires you defined train_sampler; else replace with shuffle=True\n",
    "    # shuffle=True,               # (use this instead of sampler if you don't have train_sampler)\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_dl  = DataLoader(val_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(len(train_ds), len(val_ds), len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9fae31b-d6ca-4044-b804-df3f25e53473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_153069/3015308536.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=(device.type == \"cuda\"))\n"
     ]
    }
   ],
   "source": [
    "import torch.cuda.amp as amp\n",
    "\n",
    "# Create the scaler \n",
    "scaler = amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "def run_epoch(model, loader, optimizer=None, scheduler=None):\n",
    "    train_mode = optimizer is not None\n",
    "    model.train() if train_mode else model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_targets, all_probs = [], []\n",
    "\n",
    "    # Iterate over batches\n",
    "    for imgs, targets in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        if train_mode:\n",
    "            optimizer.zero_grad(set_to_none=True) # Slightly faster than zero_grad()\n",
    "\n",
    "        # --- SPEEDUP FIX: Use Automatic Mixed Precision (AMP) ---\n",
    "        with torch.amp.autocast(device_type='cuda', enabled=(device.type == \"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = loss_function(logits, targets)\n",
    "\n",
    "        if train_mode:\n",
    "            # Use scaler to handle the lower precision math\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        # Save predictions (move to CPU to save GPU RAM)\n",
    "        with torch.no_grad():\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            all_targets.append(targets.detach().cpu().numpy())\n",
    "            all_probs.append(probs)\n",
    "\n",
    "    # Combine all batches\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "\n",
    "    return avg_loss, all_targets, all_probs\n",
    "\n",
    "def multilabel_metrics(y_true, y_prob, threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    # Per-class precision/recall/F1\n",
    "    # prec, rec, f1, support (no. occurences of each label in y_true)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n",
    "    macro_f1 = f1.mean()\n",
    "    micro_f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    # AUROC per class (guard against classes with single label value)\n",
    "    \n",
    "    aurocs = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        if len(np.unique(y_true[:, i])) == 2:\n",
    "            aurocs.append(roc_auc_score(y_true[:, i], y_prob[:, i]))\n",
    "        else:\n",
    "            aurocs.append(float('nan'))\n",
    "    return {\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"per_class_f1\": dict(zip(CLASS_ORDER, f1)),\n",
    "        \"per_class_precision\": dict(zip(CLASS_ORDER, prec)),\n",
    "        \"per_class_recall\": dict(zip(CLASS_ORDER, rec)),\n",
    "        \"per_class_auroc\": dict(zip(CLASS_ORDER, aurocs)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e80ae37-77f7-4f9a-b84e-b9b6a078c779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Warmup] Epoch 1/5\n",
      "Val macro-F1: 0.4652\n",
      "Val micro-F1: 0.4744\n",
      "\n",
      "[Warmup] Epoch 2/5\n",
      "Val macro-F1: 0.4535\n",
      "Val micro-F1: 0.4521\n",
      "\n",
      "[Warmup] Epoch 3/5\n",
      "Val macro-F1: 0.4684\n",
      "Val micro-F1: 0.4759\n",
      "\n",
      "[Warmup] Epoch 4/5\n",
      "Val macro-F1: 0.4715\n",
      "Val micro-F1: 0.4786\n",
      "\n",
      "[Warmup] Epoch 5/5\n",
      "Val macro-F1: 0.4645\n",
      "Val micro-F1: 0.4698\n",
      "\n",
      "[Fine-tune] Epoch 6/20\n",
      "Val macro-F1: 0.6265\n",
      "Val micro-F1: 0.6579\n",
      "\n",
      "[Fine-tune] Epoch 7/20\n",
      "Val macro-F1: 0.6449\n",
      "Val micro-F1: 0.6731\n",
      "\n",
      "[Fine-tune] Epoch 8/20\n",
      "Val macro-F1: 0.6573\n",
      "Val micro-F1: 0.6841\n",
      "\n",
      "[Fine-tune] Epoch 9/20\n",
      "Val macro-F1: 0.6460\n",
      "Val micro-F1: 0.6702\n",
      "\n",
      "[Fine-tune] Epoch 10/20\n",
      "Val macro-F1: 0.6763\n",
      "Val micro-F1: 0.7062\n",
      "\n",
      "[Fine-tune] Epoch 11/20\n",
      "Val macro-F1: 0.6652\n",
      "Val micro-F1: 0.6924\n",
      "\n",
      "[Fine-tune] Epoch 12/20\n",
      "Val macro-F1: 0.6802\n",
      "Val micro-F1: 0.7086\n",
      "\n",
      "[Fine-tune] Epoch 13/20\n",
      "Val macro-F1: 0.6802\n",
      "Val micro-F1: 0.7095\n",
      "\n",
      "[Fine-tune] Epoch 14/20\n",
      "Val macro-F1: 0.6877\n",
      "Val micro-F1: 0.7177\n",
      "\n",
      "[Fine-tune] Epoch 15/20\n",
      "Val macro-F1: 0.6864\n",
      "Val micro-F1: 0.7156\n",
      "\n",
      "[Fine-tune] Epoch 16/20\n",
      "Val macro-F1: 0.6868\n",
      "Val micro-F1: 0.7170\n",
      "\n",
      "[Fine-tune] Epoch 17/20\n",
      "Val macro-F1: 0.6790\n",
      "Val micro-F1: 0.7071\n",
      "\n",
      "[Fine-tune] Epoch 18/20\n",
      "Val macro-F1: 0.6994\n",
      "Val micro-F1: 0.7300\n",
      "\n",
      "[Fine-tune] Epoch 19/20\n",
      "Val macro-F1: 0.6893\n",
      "Val micro-F1: 0.7166\n",
      "\n",
      "[Fine-tune] Epoch 20/20\n",
      "Val macro-F1: 0.6794\n",
      "Val micro-F1: 0.7075\n",
      "Saved model to: /home/user/21012125/Capstone2/ecg_images/best_model_densenet121.pth\n",
      "\n",
      "Generating Loss Graph...\n",
      "Graph saved to: /home/user/21012125/Capstone2/ecg_images/loss_graph.png\n",
      "Please open this file in your file browser to view the graph.\n"
     ]
    }
   ],
   "source": [
    "# ===== Model & Loss =====\n",
    "import copy\n",
    "import matplotlib.pyplot as plt # Ensure we have this for plotting\n",
    "\n",
    "class AsymmetricLoss(nn.Module):\n",
    "    def __init__(self, gamma_pos=0.0, gamma_neg=4.0, clip=0.05, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.gamma_pos, self.gamma_neg, self.clip, self.eps = gamma_pos, gamma_neg, clip, eps\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        x_sig = torch.sigmoid(logits)\n",
    "        if self.clip and self.clip > 0:\n",
    "            x_sig = torch.clamp(x_sig, self.clip, 1.0 - self.clip)\n",
    "        xs_pos = x_sig\n",
    "        xs_neg = 1.0 - x_sig\n",
    "        w = (1 - xs_pos) ** self.gamma_pos * targets + (1 - xs_neg) ** self.gamma_neg * (1 - targets)\n",
    "        loss = - (targets * torch.log(xs_pos + self.eps) + (1 - targets) * torch.log(xs_neg + self.eps))\n",
    "        return (w * loss).mean()\n",
    "\n",
    "loss_function = AsymmetricLoss(gamma_pos=0.0, gamma_neg=4.0, clip=0.05)\n",
    "\n",
    "# # ===== ResNet34 Backbone =====\n",
    "from torchvision import models\n",
    "\n",
    "# # backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)  #restnet50 was too big, switching to resnet34\n",
    "# backbone = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    " \n",
    "# in_features = backbone.fc.in_features\n",
    "# backbone.fc = nn.Sequential(\n",
    "#     nn.Dropout(p=0.5),\n",
    "#     nn.Linear(in_features, len(CLASS_ORDER))\n",
    "# )\n",
    "# model = backbone.to(device)\n",
    "\n",
    "\n",
    "# ===== DenseNet121 Backbone ===== \n",
    "backbone = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "\n",
    "in_features = backbone.classifier.in_features\n",
    "backbone.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features, len(CLASS_ORDER))\n",
    ")\n",
    "\n",
    "model = backbone.to(device)\n",
    "\n",
    "# ===== Training setup: 2-phase (warmup + fine-tune) =====\n",
    "WARMUP_EPOCHS = 5\n",
    "TOTAL_EPOCHS  = 20\n",
    "\n",
    "# Lists to store loss history for plotting \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# ---------- PHASE 1: freeze backbone, train only the head ----------\n",
    "for name, p in model.named_parameters():\n",
    "    if name.startswith(\"classifier.\"):     # final FC layer of ResNet18\n",
    "        p.requires_grad = True\n",
    "    else:\n",
    "        p.requires_grad = False    # backbone frozen\n",
    "\n",
    "# Only head params will be trainable\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    trainable_params,\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-4,\n",
    "    steps_per_epoch=len(train_dl),\n",
    "    epochs=WARMUP_EPOCHS,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy=\"cos\",\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=10.0,\n",
    ")\n",
    "\n",
    "best_val_macro = 0.0\n",
    "best_state_dict = None\n",
    "\n",
    "for epoch in range(1, WARMUP_EPOCHS + 1):\n",
    "    print(f\"\\n[Warmup] Epoch {epoch}/{WARMUP_EPOCHS}\")\n",
    "\n",
    "    # IMPORTANT: pass scheduler into run_epoch so it can step per batch\n",
    "    train_loss, y_true_tr, y_prob_tr = run_epoch(model, train_dl, optimizer, scheduler)\n",
    "    val_loss, y_true_val, y_prob_val = run_epoch(model, val_dl, optimizer=None)\n",
    "    \n",
    "    #  Save history\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    metrics_val = multilabel_metrics(y_true_val, y_prob_val, threshold=0.5)\n",
    "    macro_f1_val  = metrics_val[\"macro_f1\"]\n",
    "    micro_f1_val  = metrics_val[\"micro_f1\"]\n",
    "    per_class_au  = metrics_val[\"per_class_auroc\"]  # this is a dict by class\n",
    "    \n",
    "    print(f\"Val macro-F1: {macro_f1_val:.4f}\")\n",
    "    print(f\"Val micro-F1: {micro_f1_val:.4f}\")\n",
    "\n",
    "    if macro_f1_val > best_val_macro:\n",
    "        best_val_macro = macro_f1_val\n",
    "        best_state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "# ---------- PHASE 2: unfreeze and fine-tune entire network ----------\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "backbone_params = []\n",
    "head_params = []\n",
    "for name, p in model.named_parameters():\n",
    "    if not p.requires_grad:\n",
    "        continue\n",
    "    if name.startswith(\"classifier.\"):\n",
    "        head_params.append(p)       # final classifier layer\n",
    "    else:\n",
    "        backbone_params.append(p)   # pretrained conv backbone\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": backbone_params, \"lr\": 5e-5, \"weight_decay\": 0.01},  # smaller LR\n",
    "        {\"params\": head_params,     \"lr\": 1e-4, \"weight_decay\": 0.01},  # larger LR\n",
    "    ]\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=5,      \n",
    "    T_mult=1,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "for epoch in range(WARMUP_EPOCHS + 1, TOTAL_EPOCHS + 1):\n",
    "    print(f\"\\n[Fine-tune] Epoch {epoch}/{TOTAL_EPOCHS}\")\n",
    "\n",
    "    train_loss, y_true_tr, y_prob_tr = run_epoch(model, train_dl, optimizer, scheduler)\n",
    "    val_loss, y_true_val, y_prob_val = run_epoch(model, val_dl, optimizer=None)\n",
    "    \n",
    "    # ### NEW CODE: Save history ###\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    metrics_val = multilabel_metrics(y_true_val, y_prob_val, threshold=0.5)\n",
    "    macro_f1_val  = metrics_val[\"macro_f1\"]\n",
    "    micro_f1_val  = metrics_val[\"micro_f1\"]\n",
    "    per_class_au  = metrics_val[\"per_class_auroc\"]  # this is a dict by class\n",
    "    \n",
    "    print(f\"Val macro-F1: {macro_f1_val:.4f}\")\n",
    "    print(f\"Val micro-F1: {micro_f1_val:.4f}\")\n",
    "\n",
    "    if macro_f1_val > best_val_macro:\n",
    "        best_val_macro = macro_f1_val\n",
    "        best_state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# After training: restore best weights before doing VAL threshold search / TEST\n",
    "model.load_state_dict(best_state_dict)\n",
    "\n",
    "#save to disk\n",
    "save_path = os.path.join(OUT_ROOT, \"best_model_densenet121.pth\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Saved model to: {save_path}\")\n",
    "\n",
    "# Plotting the graph\n",
    "print(\"\\nGenerating Loss Graph...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss', color='blue', marker='o')\n",
    "plt.plot(val_losses, label='Validation Loss', color='orange', marker='o')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot to the output folder\n",
    "graph_path = os.path.join(OUT_ROOT, \"loss_graph.png\")\n",
    "plt.savefig(graph_path)\n",
    "print(f\"Graph saved to: {graph_path}\")\n",
    "print(\"Please open this file in your file browser to view the graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e911e9-8db0-4be5-a72a-e809d93bc46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELOAD SAVED MODEL (SKIP TRAINING)\n",
    "# Run this cell to skip training and load best model\n",
    "\n",
    "model_path = os.path.join(OUT_ROOT, \"best_model_densenet121.pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Found saved model at {model_path}. Loading...\")\n",
    "    \n",
    "    # 1. Re-initialize the empty model structure \n",
    "    # (Since we ran Model Definition earlier, 'model' variable already exists)\n",
    "    \n",
    "    # 2. Load the weights from the file\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval() # Set to evaluation mode\n",
    "    print(\"Model loaded successfully! Ready for diagnosis/testing.\")\n",
    "else:\n",
    "    print(\"No saved model found. You must run the training cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2f958c8-e15e-457c-b343-ee6d2a898ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro-F1: 0.7455217979270218\n",
      "Val   macro-F1: 0.6994250161227579\n",
      "Val   micro-F1: 0.7299802461631971\n"
     ]
    }
   ],
   "source": [
    "train_loss_best, y_true_tr_best, y_prob_tr_best = run_epoch(model, train_dl, optimizer=None)\n",
    "val_loss_best,   y_true_val_best, y_prob_val_best = run_epoch(model, val_dl, optimizer=None)\n",
    "\n",
    "metrics_train = multilabel_metrics(y_true_tr_best, y_prob_tr_best, threshold=0.5)\n",
    "metrics_val   = multilabel_metrics(y_true_val_best, y_prob_val_best, threshold=0.5)\n",
    "\n",
    "print(\"Train macro-F1:\", metrics_train[\"macro_f1\"])\n",
    "print(\"Val   macro-F1:\", metrics_val[\"macro_f1\"])\n",
    "print(\"Val   micro-F1:\", metrics_val[\"micro_f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad4ffc1e-7152-4200-aee0-a208afb13739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class thresholds (VAL, CLASS_ORDER): {'NORM': np.float32(0.6), 'MI': np.float32(0.65), 'STTC': np.float32(0.65), 'HYP': np.float32(0.6), 'CD': np.float32(0.6)}\n",
      "\n",
      "[Test @ 0.5] Macro-F1: 0.7016\n",
      "[Test @ 0.5] Micro-F1: 0.7325\n",
      "Per-class F1 @ 0.5: {'NORM': np.float64(0.8639391056137012), 'MI': np.float64(0.676056338028169), 'STTC': np.float64(0.709628506444276), 'HYP': np.float64(0.5671232876712329), 'CD': np.float64(0.6911764705882353)}\n",
      "Per-class AUROC: {'NORM': 0.9414725600351066, 'MI': 0.8931829488919041, 'STTC': 0.9274719566830856, 'HYP': 0.9105781154378845, 'CD': 0.8835649091650168}\n",
      "\n",
      "[Test @ tuned thresholds] Macro-F1 (tuned): 0.7248\n",
      "Per-class F1 (tuned): {'NORM': np.float64(0.8578603716725264), 'MI': np.float64(0.6955736224028907), 'STTC': np.float64(0.746268656716418), 'HYP': np.float64(0.6039076376554174), 'CD': np.float64(0.7201783723522854)}\n",
      "Per-class thresholds (CLASS_ORDER): {'NORM': np.float32(0.6), 'MI': np.float32(0.65), 'STTC': np.float32(0.65), 'HYP': np.float32(0.6), 'CD': np.float32(0.6)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def best_thresholds_per_class(y_true_val, y_prob_val, grid=np.linspace(0.05, 0.95, 19)):\n",
    "    C = y_true_val.shape[1]\n",
    "    best = np.full(C, 0.5, dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        yt, yp = y_true_val[:, c], y_prob_val[:, c]\n",
    "        if len(np.unique(yt)) < 2:   # cannot tune if constant\n",
    "            continue\n",
    "        f1_best, thr_best = -1.0, 0.5\n",
    "        for t in grid:\n",
    "            f1 = f1_score(yt, (yp >= t).astype(int), zero_division=0)\n",
    "            if f1 > f1_best:\n",
    "                f1_best, thr_best = f1, t\n",
    "        best[c] = thr_best\n",
    "    return best\n",
    "\n",
    "# ---- VAL: find best threshold per class ----\n",
    "val_loss, y_true_val, y_prob_val = run_epoch(model, val_dl, optimizer=None)\n",
    "per_class_thr = best_thresholds_per_class(y_true_val, y_prob_val)\n",
    "print(\"Per-class thresholds (VAL, CLASS_ORDER):\", dict(zip(CLASS_ORDER, per_class_thr)))\n",
    "\n",
    "# ---- TEST: evaluate with base 0.5 threshold ----\n",
    "test_loss, y_true_test, y_prob_test = run_epoch(model, test_dl, optimizer=None)\n",
    "\n",
    "metrics_test = multilabel_metrics(y_true_test, y_prob_test, threshold=0.5)\n",
    "macro_f1_05  = metrics_test[\"macro_f1\"]\n",
    "micro_f1_05  = metrics_test[\"micro_f1\"]\n",
    "\n",
    "print(f\"\\n[Test @ 0.5] Macro-F1: {macro_f1_05:.4f}\")\n",
    "print(f\"[Test @ 0.5] Micro-F1: {micro_f1_05:.4f}\")\n",
    "print(\"Per-class F1 @ 0.5:\", metrics_test[\"per_class_f1\"])\n",
    "print(\"Per-class AUROC:\", metrics_test[\"per_class_auroc\"])\n",
    "\n",
    "# ---- TEST: evaluate with tuned thresholds from VAL ----\n",
    "# per_class_thr is already aligned with CLASS_ORDER, same as y_prob_test columns\n",
    "y_pred_test_tuned = (y_prob_test >= per_class_thr[None, :]).astype(int)\n",
    "\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    y_true_test, y_pred_test_tuned, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "per_class_f1_tuned = dict(zip(CLASS_ORDER, f1))\n",
    "macro_f1_tuned = float(np.mean(f1))\n",
    "\n",
    "print(f\"\\n[Test @ tuned thresholds] Macro-F1 (tuned): {macro_f1_tuned:.4f}\")\n",
    "print(\"Per-class F1 (tuned):\", per_class_f1_tuned)\n",
    "print(\"Per-class thresholds (CLASS_ORDER):\", dict(zip(CLASS_ORDER, per_class_thr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df57c5c6-1131-4dae-b520-1c25d62621e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exact-match accuracy @ 0.5: 43.61%\n",
      "Label-wise mean accuracy @ 0.5: 83.49%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "FINE tuning:\n",
    "0. epochs\n",
    "1. dropout\n",
    "2. lr\n",
    "3. weight decay\n",
    "4. factor (scheduler)\n",
    "6. patience (scheduler)\n",
    "7. more feature classes in ConvBlock\n",
    "8. more layers for convblock\n",
    "9. image augmentation\n",
    "10. increase data size, increase image resolution, change to higher bitrate\n",
    "\"\"\"\n",
    "\n",
    "# Extra metrics at 0.5 threshold \n",
    "threshold = 0.5\n",
    "y_pred_test_05 = (y_prob_test >= threshold).astype(int)\n",
    "exact_match = np.all(y_pred_test_05 == y_true_test, axis=1)\n",
    "exact_acc = exact_match.mean() * 100\n",
    "labelwise_acc = (y_pred_test_05 == y_true_test).mean() * 100\n",
    "\n",
    "print(f\"\\nExact-match accuracy @ 0.5: {exact_acc:.2f}%\")\n",
    "print(f\"Label-wise mean accuracy @ 0.5: {labelwise_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f3aef7c-5ee9-4c68-83d0-df2c59e450e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[VAL @ 0.5] Exact-match accuracy: 44.50%\n",
      "[VAL @ 0.5] Label-wise mean accuracy: 83.44%\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_pred_val_05 = (y_prob_val >= threshold).astype(int)\n",
    "\n",
    "# Exact-match: all labels for a sample must be correct\n",
    "exact_match_val = np.all(y_pred_val_05 == y_true_val, axis=1)\n",
    "exact_acc_val = exact_match_val.mean() * 100\n",
    "\n",
    "# Label-wise mean accuracy: average over all label positions\n",
    "labelwise_acc_val = (y_pred_val_05 == y_true_val).mean() * 100\n",
    "\n",
    "print(f\"\\n[VAL @ 0.5] Exact-match accuracy: {exact_acc_val:.2f}%\")\n",
    "print(f\"[VAL @ 0.5] Label-wise mean accuracy: {labelwise_acc_val:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c498d7ba-6d96-4de0-b491-ccf44185ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test @ threshold=0.5 ===\n",
      "MacroF1: 0.701584741669123\n",
      "Per-class F1: {'NORM': np.float64(0.8639391056137012), 'MI': np.float64(0.676056338028169), 'STTC': np.float64(0.709628506444276), 'HYP': np.float64(0.5671232876712329), 'CD': np.float64(0.6911764705882353)}\n"
     ]
    }
   ],
   "source": [
    "# After compute test_loss, y_true_test, y_prob_test\n",
    "metrics_test_05 = multilabel_metrics(y_true_test, y_prob_test, threshold=0.5)\n",
    "print(\"=== Test @ threshold=0.5 ===\")\n",
    "print(\"MacroF1:\", metrics_test_05[\"macro_f1\"])\n",
    "print(\"Per-class F1:\", metrics_test_05[\"per_class_f1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c37a247-c9ee-48b9-afa8-7438885aedac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL positives: {'NORM': np.float32(955.0), 'MI': np.float32(540.0), 'STTC': np.float32(528.0), 'HYP': np.float32(268.0), 'CD': np.float32(495.0)}\n",
      "TEST positives: {'NORM': np.float32(963.0), 'MI': np.float32(550.0), 'STTC': np.float32(521.0), 'HYP': np.float32(262.0), 'CD': np.float32(496.0)}\n"
     ]
    }
   ],
   "source": [
    "val_support = y_true_val.sum(axis=0)\n",
    "test_support = y_true_test.sum(axis=0)\n",
    "print(\"VAL positives:\", dict(zip(CLASS_ORDER, val_support)))\n",
    "print(\"TEST positives:\", dict(zip(CLASS_ORDER, test_support)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6c340eb-c962-4adc-8043-8f34990a1690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best global t on VAL: 0.6 macroF1: 0.7258694532955733\n",
      "MacroF1 TEST @ global t: 0.7232039270172734\n",
      "Per-class F1 TEST @ global t: {'NORM': np.float64(0.8578603716725264), 'MI': np.float64(0.6834170854271356), 'STTC': np.float64(0.7506561679790026), 'HYP': np.float64(0.6039076376554174), 'CD': np.float64(0.7201783723522854)}\n"
     ]
    }
   ],
   "source": [
    "def best_global_threshold(y_true, y_prob, grid=np.linspace(0.1, 0.9, 17)):\n",
    "    best_t, best_f1 = 0.5, -1\n",
    "    for t in grid:\n",
    "        f1 = f1_score(y_true, (y_prob >= t).astype(int), average=\"macro\", zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    return best_t, best_f1\n",
    "\n",
    "t_global, f1_global_val = best_global_threshold(y_true_val, y_prob_val)\n",
    "print(\"Best global t on VAL:\", t_global, \"macroF1:\", f1_global_val)\n",
    "\n",
    "y_pred_test_global = (y_prob_test >= t_global).astype(int)\n",
    "_, _, f1_test_global, _ = precision_recall_fscore_support(\n",
    "    y_true_test, y_pred_test_global, average=None, zero_division=0\n",
    ")\n",
    "print(\"MacroF1 TEST @ global t:\", float(f1_test_global.mean()))\n",
    "print(\"Per-class F1 TEST @ global t:\", dict(zip(CLASS_ORDER, f1_test_global)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e52d8d25-a0a1-47f9-ba20-7b947bb981a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting predictions for diagnosis...\n",
      "Found 102 HYP cases that were MISSED (False Negatives).\n",
      "Showing top 3 with highest confidence in being 'Normal'...\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def diagnose_hyp_errors(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    print(\"Collecting predictions for diagnosis...\")\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            logits = model(imgs)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            \n",
    "            all_preds.append(probs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    y_prob = np.concatenate(all_preds)\n",
    "    y_true = np.concatenate(all_targets)\n",
    "    \n",
    "    # --- 1. Confusion Matrix for HYP ---\n",
    "    # HYP is index 3 in CLASS_ORDER = [\"NORM\", \"MI\", \"STTC\", \"HYP\", \"CD\"]\n",
    "    hyp_idx = 3\n",
    "    hyp_true = y_true[:, hyp_idx]\n",
    "    hyp_pred = (y_prob[:, hyp_idx] >= threshold).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(hyp_true, hyp_pred)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted No-HYP', 'Predicted HYP'],\n",
    "                yticklabels=['Actual No-HYP', 'Actual HYP'])\n",
    "    plt.title('Confusion Matrix for Hypertrophy (HYP)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    # Save the Confusion Matrix\n",
    "    plt.savefig(os.path.join(OUT_ROOT, \"hyp_confusion_matrix.png\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # --- 2. Visualize False Negatives (The \"Missed\" Cases) ---\n",
    "    # Find indices where True=1 but Pred=0\n",
    "    fn_indices = np.where((hyp_true == 1) & (hyp_pred == 0))[0]\n",
    "    \n",
    "    print(f\"Found {len(fn_indices)} HYP cases that were MISSED (False Negatives).\")\n",
    "    print(\"Showing top 3 with highest confidence in being 'Normal'...\")\n",
    "    \n",
    "    # Sort by how \"wrong\" the model was (lowest probability for HYP)\n",
    "    worst_misses = fn_indices[np.argsort(y_prob[fn_indices, hyp_idx])[:3]]\n",
    "    \n",
    "    # We need to fetch images from the dataset wrapper to visualize them\n",
    "    # Note: We will use the Validation Dataset (val_ds)\n",
    "    for i, idx in enumerate(worst_misses):\n",
    "        img_tensor, _ = val_ds[idx] \n",
    "        \n",
    "        # Simple denormalize for visualization (approximate)\n",
    "        img_disp = img_tensor.permute(1, 2, 0).numpy()\n",
    "        img_disp = (img_disp * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n",
    "        img_disp = np.clip(img_disp, 0, 1)\n",
    "        \n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.imshow(img_disp)\n",
    "        plt.title(f\"Missed HYP Case #{idx} | Model Prob for HYP: {y_prob[idx, hyp_idx]:.4f}\")\n",
    "        plt.axis('off')\n",
    "        # Save the missed case image\n",
    "        plt.savefig(os.path.join(OUT_ROOT, f\"missed_hyp_case_{i+1}.png\"))\n",
    "        plt.show()\n",
    "\n",
    "# Run the function using your validation loader\n",
    "diagnose_hyp_errors(model, val_dl, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "044fd766-c1ae-44e6-982e-e9b8d906c767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /home/user/21012125/Capstone2/ecg_images. Ready to regenerate.\n"
     ]
    }
   ],
   "source": [
    "#this is to delete images in ecg_images for resetting\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# if os.path.exists(OUT_ROOT):\n",
    "#     shutil.rmtree(OUT_ROOT)\n",
    "#     print(f\"Deleted {OUT_ROOT}. Ready to regenerate.\")\n",
    "# os.makedirs(OUT_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff8794-87ab-4884-9088-801bcf72acc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
